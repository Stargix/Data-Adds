{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7055d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae031c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar ruta y cargar subset pequeño de datos\n",
    "train_path = '/home/stargix/Desktop/hackathons/datathon/train/train'\n",
    "\n",
    "# Obtener lista de archivos parquet\n",
    "parquet_files = glob(os.path.join(train_path, '**/part-*.parquet'), recursive=True)\n",
    "print(f\"Total de archivos parquet: {len(parquet_files)}\")\n",
    "\n",
    "# Usar solo los primeros 5 archivos para entrenar (subset pequeño)\n",
    "sample_files = parquet_files[:5]\n",
    "print(f\"Usando {len(sample_files)} archivos para entrenamiento\")\n",
    "\n",
    "# Cargar y combinar datos\n",
    "dfs = []\n",
    "for file in sample_files:\n",
    "    df = pd.read_parquet(file)\n",
    "    dfs.append(df)\n",
    "    print(f\"Cargado: {os.path.basename(os.path.dirname(file))}, shape: {df.shape}\")\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nDatos combinados - Shape: {data.shape}\")\n",
    "print(f\"Columnas: {data.columns.tolist()}\")\n",
    "print(f\"\\nPrimeras filas:\\n{data.head()}\")\n",
    "print(f\"\\nInfo de tipos:\\n{data.dtypes}\")\n",
    "print(f\"\\nValores faltantes:\\n{data.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efbbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para la red neuronal\n",
    "# Separar features y target (asumiendo que 'revenue' es el target)\n",
    "\n",
    "# Seleccionar features numéricos\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Identificar la columna target (revenue)\n",
    "if 'revenue' in numeric_cols:\n",
    "    target_col = 'revenue'\n",
    "    feature_cols = [col for col in numeric_cols if col != 'revenue']\n",
    "else:\n",
    "    print(\"Columnas disponibles:\", numeric_cols)\n",
    "    target_col = numeric_cols[-1]\n",
    "    feature_cols = numeric_cols[:-1]\n",
    "\n",
    "print(f\"Target: {target_col}\")\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols}\")\n",
    "\n",
    "# Preparar X (features) e y (target)\n",
    "X = data[feature_cols].values.astype(np.float32)\n",
    "y = data[target_col].values.astype(np.float32)\n",
    "\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"Rango de revenue: [{y.min():.2f}, {y.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X).astype(np.float32)\n",
    "\n",
    "# Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Shape de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Shape de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).reshape(-1, 1).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).reshape(-1, 1).to(device)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"\\nTensores creados en dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61224793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir arquitectura de red neuronal con PyTorch\n",
    "class RevenueNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RevenueNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.relu3(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "input_dim = X_train.shape[1]\n",
    "model = RevenueNN(input_dim).to(device)\n",
    "\n",
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Arquitectura del modelo:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal de parámetros: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a95f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Validación\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_test_tensor)\n",
    "        val_loss = criterion(val_predictions, y_test_tensor)\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Época {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f} - Val Loss: {val_loss.item():.4f}\")\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "print(\"\\nEntrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bfb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en datos de prueba\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    test_loss = criterion(y_pred_tensor, y_test_tensor)\n",
    "\n",
    "y_pred = y_pred_tensor.cpu().numpy()\n",
    "test_mse = test_loss.item()\n",
    "test_mae = torch.abs(y_pred_tensor - y_test_tensor).mean().item()\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(f\"Resultados en datos de prueba:\")\n",
    "print(f\"Pérdida (MSE): {test_mse:.4f}\")\n",
    "print(f\"MAE: {test_mae:.4f}\")\n",
    "print(f\"RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Mostrar algunas predicciones vs valores reales\n",
    "print(f\"\\nPrimeras 10 predicciones vs valores reales:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Real': y_test[:10],\n",
    "    'Predicho': y_pred[:10].flatten(),\n",
    "    'Error': np.abs(y_test[:10] - y_pred[:10].flatten())\n",
    "})\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e371da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar el histórico de entrenamiento\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(train_losses, label='Pérdida de Entrenamiento')\n",
    "axes[0].plot(val_losses, label='Pérdida de Validación')\n",
    "axes[0].set_xlabel('Época')\n",
    "axes[0].set_ylabel('Pérdida (MSE)')\n",
    "axes[0].set_title('Histórico de Pérdida')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Predicciones vs Reales\n",
    "axes[1].scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Valores Reales')\n",
    "axes[1].set_ylabel('Predicciones')\n",
    "axes[1].set_title('Predicciones vs Valores Reales')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Gráficos de entrenamiento generados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para hacer predicciones en nuevos datos\n",
    "def predecir_revenue(ids, features_dict):\n",
    "    \"\"\"\n",
    "    Predecir revenue para un subset de datos\n",
    "    ids: lista de IDs\n",
    "    features_dict: diccionario con features\n",
    "    \"\"\"\n",
    "    # Crear dataframe\n",
    "    df_nuevo = pd.DataFrame(features_dict)\n",
    "    \n",
    "    # Usar solo los features que se usaron en entrenamiento\n",
    "    X_nuevo = df_nuevo[feature_cols].values.astype(np.float32)\n",
    "    \n",
    "    # Normalizar con el mismo scaler\n",
    "    X_nuevo_scaled = scaler.transform(X_nuevo).astype(np.float32)\n",
    "    \n",
    "    # Convertir a tensor\n",
    "    X_nuevo_tensor = torch.FloatTensor(X_nuevo_scaled).to(device)\n",
    "    \n",
    "    # Predecir\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicciones = model(X_nuevo_tensor)\n",
    "    \n",
    "    # Convertir resultado a numpy\n",
    "    predicciones_np = predicciones.cpu().numpy()\n",
    "    \n",
    "    # Crear resultado\n",
    "    resultado = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'revenue_predicho': predicciones_np.flatten()\n",
    "    })\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "# Ejemplo de predicción con datos nuevos\n",
    "example_ids = list(range(1, 6))\n",
    "example_features = {col: X_test[:5, feature_cols.index(col)] for col in feature_cols}\n",
    "\n",
    "predicciones_ejemplo = predecir_revenue(example_ids, example_features)\n",
    "print(\"Ejemplo de predicciones:\")\n",
    "print(predicciones_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'revenue_model.pth')\n",
    "print(\"Modelo guardado como 'revenue_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
