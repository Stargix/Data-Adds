{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a32808",
   "metadata": {},
   "source": [
    "# Teacher (DNN) → Student (Tiny DNN) Distillation pipeline\n",
    "\n",
    "**Objetivo:** entrenar una DNN *teacher* más grande offline y luego distilar su conocimiento a un *student* pequeño y rápido para predicción de `iap_revenue_d7` (target).\n",
    "\n",
    "Este notebook está diseñado para datasets tabulares como el del hackathon (features de request + historial de usuario). Incluye:\n",
    "- carga y preprocesado (intenta detectar archivos en `/mnt/data`)\n",
    "- definición de modelos en **PyTorch** (teacher y student)\n",
    "- esquema de entrenamiento del teacher (rápido, ejemplar)\n",
    "- esquema de distillation (loss combinado: `L_hard + L_soft`)\n",
    "- evaluación básica (MSLE y AUC para buyer flag)\n",
    "\n",
    "> Nota: Este notebook se entrega como plantilla lista para ejecutar. Ajusta hiperparámetros, dimensiones de embeddings y número de épocas según tu hardware y tamaño del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "\n",
    "# Reproducibility\n",
    "RSEED = 42\n",
    "np.random.seed(RSEED)\n",
    "torch.manual_seed(RSEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to locate a dataset in /mnt/data\n",
    "candidates = [f for f in os.listdir('/mnt/data') if f.lower().endswith(('.csv', '.parquet', '.feather', '.pkl', '.zip'))]\n",
    "print('Datasets found in /mnt/data:', candidates)\n",
    "\n",
    "data_path = None\n",
    "if candidates:\n",
    "    data_path = os.path.join('/mnt/data', candidates[0])\n",
    "\n",
    "if data_path is None:\n",
    "    print('No dataset found in /mnt/data. The notebook will create a SMALL synthetic dataset for demonstration. Replace it with your real dataset.')\n",
    "else:\n",
    "    print('Using dataset:', data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset or create synthetic\n",
    "if data_path is not None:\n",
    "    if data_path.lower().endswith('.csv'):\n",
    "        data = pd.read_csv(data_path)\n",
    "    elif data_path.lower().endswith('.parquet'):\n",
    "        data = pd.read_parquet(data_path)\n",
    "    elif data_path.lower().endswith('.pkl'):\n",
    "        data = pd.read_pickle(data_path)\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "else:\n",
    "    # Create a small synthetic dataset for demonstration\n",
    "    N = 20000\n",
    "    rng = np.random.RandomState(RSEED)\n",
    "    data = pd.DataFrame({\n",
    "        'device_model': rng.choice([f'dm_{i}' for i in range(200)], size=N),\n",
    "        'os_version': rng.choice([f'os_{i}' for i in range(10)], size=N),\n",
    "        'country': rng.choice(['US','BR','IN','DE','FR','CN'], size=N),\n",
    "        'hour': rng.randint(0,24,size=N),\n",
    "        'past_purchases': rng.poisson(0.2, size=N),\n",
    "        'avg_spend_30d': rng.exponential(5.0, size=N),\n",
    "        'imp_count_7d': rng.poisson(3, size=N),\n",
    "    })\n",
    "    buyer_prob = 1 / (1 + np.exp(-(-2 + 0.05*data['past_purchases'] + 0.01*data['imp_count_7d'])))\n",
    "    is_buyer = rng.binomial(1, buyer_prob)\n",
    "    revenue = is_buyer * np.exp(rng.normal(np.log(5+data['avg_spend_30d']), 1.0)) * rng.choice([0.5,1,2,5], size=N, p=[0.5,0.3,0.15,0.05])\n",
    "    revenue = np.clip(revenue, 0, None)\n",
    "    data['buyer_d7'] = is_buyer\n",
    "    data['iap_revenue_d7'] = revenue\n",
    "    print('Synthetic data created.')\n",
    "\n",
    "print('Data shape:', data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285425b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing: detect categorical and numeric features, prepare target\n",
    "target_col = 'iap_revenue_d7' if 'iap_revenue_d7' in data.columns else data.select_dtypes(include=[np.number]).columns[-1]\n",
    "buyer_col = 'buyer_d7' if 'buyer_d7' in data.columns else None\n",
    "\n",
    "# Identify categorical columns (object or low-cardinality)\n",
    "cat_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# also treat low-cardinality ints as categorical\n",
    "for c in data.select_dtypes(include=['int64','int32']).columns:\n",
    "    if c != target_col and data[c].nunique() <= 50 and c not in cat_cols and c != buyer_col:\n",
    "        cat_cols.append(c)\n",
    "        \n",
    "num_cols = [c for c in data.select_dtypes(include=[np.number]).columns.tolist() if c not in [target_col, buyer_col] and c not in cat_cols]\n",
    "\n",
    "print('Target:', target_col)\n",
    "print('Buyer flag:', buyer_col)\n",
    "print('Categorical columns:', cat_cols)\n",
    "print('Numeric columns:', num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fillna\n",
    "if len(cat_cols)>0:\n",
    "    data[cat_cols] = data[cat_cols].fillna('NA')\n",
    "if len(num_cols)>0:\n",
    "    data[num_cols] = data[num_cols].fillna(0.0)\n",
    "\n",
    "# Label encode categoricals and save encoders\n",
    "encoders = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[c] = le.fit_transform(data[c].astype(str))\n",
    "    encoders[c] = le\n",
    "\n",
    "# Target transform: log1p for stability (MSLE)\n",
    "data['target_log1p'] = np.log1p(data[target_col].clip(lower=0.0))\n",
    "\n",
    "# Train/val split (stratify by buyer if available)\n",
    "if buyer_col is not None:\n",
    "    train_df, val_df = train_test_split(data, test_size=0.15, random_state=RSEED, stratify=data[buyer_col])\n",
    "else:\n",
    "    train_df, val_df = train_test_split(data, test_size=0.15, random_state=RSEED)\n",
    "\n",
    "print('Train shape:', train_df.shape, 'Val shape:', val_df.shape)\n",
    "\n",
    "# Save encoders for later use\n",
    "joblib.dump(encoders, '/mnt/data/encoders_joblib.pkl')\n",
    "print('Encoders saved to /mnt/data/encoders_joblib.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab6b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset for tabular data with categorical embeddings\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, df, cat_cols, num_cols, target_col, buyer_col=None):\n",
    "        self.cat = df[cat_cols].values.astype(np.int64) if len(cat_cols)>0 else None\n",
    "        self.num = df[num_cols].values.astype(np.float32) if len(num_cols)>0 else None\n",
    "        self.y = df[target_col].values.astype(np.float32)\n",
    "        self.buyer = df[buyer_col].values.astype(np.int64) if buyer_col is not None else None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        if self.cat is not None:\n",
    "            item['cat'] = torch.tensor(self.cat[idx], dtype=torch.long)\n",
    "        if self.num is not None:\n",
    "            item['num'] = torch.tensor(self.num[idx], dtype=torch.float32)\n",
    "        item['y'] = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        if self.buyer is not None:\n",
    "            item['buyer'] = torch.tensor(self.buyer[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "# Create datasets and dataloaders (small batch sizes)\n",
    "train_ds = TabularDataset(train_df, cat_cols, num_cols, 'target_log1p', buyer_col)\n",
    "val_ds = TabularDataset(val_df, cat_cols, num_cols, 'target_log1p', buyer_col)\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "print('Dataloaders ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ec01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model utilities: Embedding sizes rule\n",
    "def get_embedding_sizes(df, cat_cols, max_emb_dim=50):\n",
    "    emb_sizes = []\n",
    "    for c in cat_cols:\n",
    "        n_unique = int(df[c].nunique())\n",
    "        emb_dim = min(max(1, n_unique//10), max_emb_dim)\n",
    "        emb_sizes.append((n_unique, emb_dim))\n",
    "    return emb_sizes\n",
    "\n",
    "# Teacher model (bigger)\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, num_len):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(categories, dim) for categories, dim in emb_sizes])\n",
    "        emb_dim_sum = sum([dim for _, dim in emb_sizes]) if len(emb_sizes)>0 else 0\n",
    "        input_dim = emb_dim_sum + (num_len if num_len>0 else 0)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        self.buyer_head = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_cat, x_num):\n",
    "        if x_cat is not None and len(self.embs)>0:\n",
    "            embs = [emb(x_cat[:,i]) for i, emb in enumerate(self.embs)]\n",
    "            x = torch.cat(embs + ([x_num] if x_num is not None else []), dim=1)\n",
    "        else:\n",
    "            x = x_num\n",
    "        feat = self.net[:-1](x) if isinstance(self.net, nn.Sequential) else self.net(x)\n",
    "        out_reg = self.net[-1](feat) if isinstance(self.net, nn.Sequential) else self.net(x)\n",
    "        out_buyer = self.buyer_head(feat)\n",
    "        return out_reg.view(-1), out_buyer.view(-1)\n",
    "\n",
    "# Student model (small)\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self, emb_sizes, num_len):\n",
    "        super().__init__()\n",
    "        small_embs = [(n, max(1, d//2)) for n,d in emb_sizes]\n",
    "        self.embs = nn.ModuleList([nn.Embedding(categories, dim) for categories, dim in small_embs])\n",
    "        emb_dim_sum = sum([dim for _, dim in small_embs]) if len(small_embs)>0 else 0\n",
    "        input_dim = emb_dim_sum + (num_len if num_len>0 else 0)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x_cat, x_num):\n",
    "        if x_cat is not None and len(self.embs)>0:\n",
    "            embs = [emb(x_cat[:,i]) for i, emb in enumerate(self.embs)]\n",
    "            x = torch.cat(embs + ([x_num] if x_num is not None else []), dim=1)\n",
    "        else:\n",
    "            x = x_num\n",
    "        out = self.net(x)\n",
    "        return out.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f243ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sizes = get_embedding_sizes(train_df, cat_cols, max_emb_dim=50)\n",
    "print('Embedding sizes (categories, dim):', emb_sizes)\n",
    "\n",
    "teacher = TeacherModel(emb_sizes, len(num_cols)).to('cpu')\n",
    "student = StudentModel(emb_sizes, len(num_cols)).to('cpu')\n",
    "\n",
    "print('Teacher params:', sum(p.numel() for p in teacher.parameters() if p.requires_grad))\n",
    "print('Student params:', sum(p.numel() for p in student.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1110b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training skeleton for teacher\n",
    "def train_teacher(model, loader, val_loader, epochs=3, lr=1e-3, device='cpu'):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    bce_loss = nn.BCELoss()\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in loader:\n",
    "            x_cat = batch.get('cat', None).to(device) if 'cat' in batch else None\n",
    "            x_num = batch.get('num', None).to(device) if 'num' in batch else None\n",
    "            y = batch['y'].to(device)\n",
    "            buyer = batch.get('buyer', None)\n",
    "            buyer = buyer.to(device) if buyer is not None else None\n",
    "            opt.zero_grad()\n",
    "            pred_log1p, pred_buyer = model(x_cat, x_num)\n",
    "            loss_reg = mse_loss(pred_log1p, y)\n",
    "            loss_buyer = bce_loss(pred_buyer, buyer) if buyer is not None else 0.0\n",
    "            loss = loss_reg + 0.5 * loss_buyer\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item() * len(y)\n",
    "        train_loss /= len(loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs} train_loss={train_loss:.6f}')\n",
    "    torch.save(model.state_dict(), '/mnt/data/teacher_model.pt')\n",
    "    print('Teacher saved to /mnt/data/teacher_model.pt')\n",
    "\n",
    "print('Teacher training function defined. (call train_teacher(...) to run)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098df9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distillation\n",
    "def train_student_with_distillation(student, teacher, train_loader, val_loader, epochs=3, lr=1e-3, alpha=0.6, device='cpu'):\n",
    "    opt = torch.optim.Adam(student.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    mse = nn.MSELoss()\n",
    "    teacher.to(device)\n",
    "    teacher.eval()\n",
    "    student.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            x_cat = batch.get('cat', None).to(device) if 'cat' in batch else None\n",
    "            x_num = batch.get('num', None).to(device) if 'num' in batch else None\n",
    "            y = batch['y'].to(device)\n",
    "            with torch.no_grad():\n",
    "                t_pred_log1p, t_pred_buyer = teacher(x_cat, x_num)\n",
    "            s_pred = student(x_cat, x_num)\n",
    "            loss_hard = mse(s_pred, y)\n",
    "            loss_soft = mse(s_pred, t_pred_log1p)\n",
    "            loss = alpha * loss_hard + (1.0 - alpha) * loss_soft\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * len(y)\n",
    "        total_loss /= len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs} distill_loss={total_loss:.6f}')\n",
    "    torch.save(student.state_dict(), '/mnt/data/student_model.pt')\n",
    "    print('Student saved to /mnt/data/student_model.pt')\n",
    "\n",
    "print('Distillation training function defined. (call train_student_with_distillation(...) to run)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation utilities\n",
    " def predict_model_regression(model, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    buyers = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x_cat = batch.get('cat', None).to(device) if 'cat' in batch else None\n",
    "            x_num = batch.get('num', None).to(device) if 'num' in batch else None\n",
    "            y = batch['y'].to(device)\n",
    "            out = model(x_cat, x_num)\n",
    "            preds.append(out.cpu().numpy())\n",
    "            trues.append(y.cpu().numpy())\n",
    "            if 'buyer' in batch:\n",
    "                buyers.append(batch['buyer'].numpy())\n",
    "    preds = np.concatenate(preds).ravel()\n",
    "    trues = np.concatenate(trues).ravel()\n",
    "    buyers = np.concatenate(buyers).ravel() if buyers else None\n",
    "    return preds, trues, buyers\n",
    "\n",
    "def msle_from_log_predictions(pred_log1p, true_log1p):\n",
    "    pred = np.expm1(pred_log1p)\n",
    "    true = np.expm1(true_log1p)\n",
    "    pred = np.clip(pred, 0, None)\n",
    "    true = np.clip(true, 0, None)\n",
    "    return mean_squared_log_error(true, pred)\n",
    "\n",
    "print('Evaluation utilities defined.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d590f",
   "metadata": {},
   "source": [
    "## Cómo usar este notebook\n",
    "\n",
    "1. Si tienes un dataset, colócalo en `/mnt/data` (CSV o parquet). El notebook auto-detecta archivos ahí.  \n",
    "2. Ajusta `cat_cols` y `num_cols` si lo deseas (el notebook intenta detectarlos automáticamente).  \n",
    "3. Entrena el **teacher** (p. ej. `train_teacher(teacher, train_loader, val_loader, epochs=5, lr=1e-3)`).  \n",
    "4. Después, entrena al **student** con distillation (`train_student_with_distillation(student, teacher, train_loader, val_loader, epochs=5, alpha=0.6)`).  \n",
    "5. Evalúa usando las funciones de evaluación o guarda modelos para exportar.  \n",
    "\n",
    "**Tips**:\n",
    "- Para producción, guarda sólo el `student` y exporta a ONNX + quantization.\n",
    "- Ajusta `emb_sizes` rule para reducir dims en el student y acelerar inferencia.\n",
    "- Considera usar `log1p` y MSLE en todas las fases.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
